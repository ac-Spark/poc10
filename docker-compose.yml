services:
  backend:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: hunyuan3d-2.1
    ports:
      - "${EXTERNAL_PORT}:${PORT}"
    volumes:
      - .:/workspace/Hunyuan3D-2.1
      - ./gradio_cache:/workspace/Hunyuan3D-2.1/gradio_cache
      - ./hf_cache:/workspace/hf_cache
      - /home/human/.cache:/root/.cache
    environment:
      - NVIDIA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES}
      - PYTORCH_CUDA_ALLOC_CONF=${PYTORCH_CUDA_ALLOC_CONF}
      - CUDA_LAUNCH_BLOCKING=1
      - TORCH_CUDNN_V8_API_ENABLED=1
      - HF_HOME=${HF_HOME}
      - TRANSFORMERS_CACHE=${TRANSFORMERS_CACHE}
      - DIFFUSERS_CACHE=${DIFFUSERS_CACHE}
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_TOKEN=${HF_TOKEN}
      - LOW_VRAM_MODE=${LOW_VRAM_MODE}
      - HOST=${HOST}
      - PORT=${PORT}
      - MODEL_PATH=${MODEL_PATH}
      - SUBFOLDER=${SUBFOLDER}
      - CUDA_LAUNCH_BLOCKING=0
      - PYTORCH_CUDA_ALLOC_CONF=${PYTORCH_CUDA_ALLOC_CONF}
      - CUDA_MEMORY_FRACTION=0.8
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    stdin_open: true
    tty: true
    shm_size: 16gb
    ulimits:
      memlock: -1
      stack: 67108864
    networks:
      - hunyuan3d

  frontend:
    image: python:3.10-slim
    container_name: hunyuan3d-frontend
    working_dir: /app
    command: bash -c "pip install python-dotenv && python server.py"
    ports:
      - "${FRONTEND_PORT}:8861"
    volumes:
      - ./frontend:/app
    environment:
      - API_BASE_URL=http://backend:8860
      - FRONTEND_PORT=8861
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - hunyuan3d

networks:
  hunyuan3d:
    driver: bridge